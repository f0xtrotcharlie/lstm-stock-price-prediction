{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eab06d-013d-44d9-a714-04102728497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# List of stock tickers to process\n",
    "# stock_list = ['AAPL', 'TSLA']\n",
    "\n",
    "# Directories for input, output, models, and scalers\n",
    "processed_data_dir = \"..//data//processed//\"\n",
    "models_dir = \"..//models//\"\n",
    "output_dir = \"..//data//results//\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for ticker in stock_list:\n",
    "        try:\n",
    "            print(f\"Processing {ticker}...\")\n",
    "\n",
    "            # File paths\n",
    "            train_file = f\"{processed_data_dir}{ticker.lower()}_stock_price_processed_train.csv\"\n",
    "            validate_file = f\"{processed_data_dir}{ticker.lower()}_stock_price_processed_validate.csv\"\n",
    "            test_file = f\"{processed_data_dir}{ticker.lower()}_stock_price_processed_test.csv\"\n",
    "            scaler_file = f\"{models_dir}{ticker.lower()}_stock_price_scaler.gz\"\n",
    "            model_file = f\"{models_dir}{ticker.lower()}_stock_price_lstm.model.keras\"\n",
    "\n",
    "            # Load processed data\n",
    "            data_train_df = pd.read_csv(train_file)\n",
    "            data_validate_df = pd.read_csv(validate_file)\n",
    "            data_test_df = pd.read_csv(test_file)\n",
    "\n",
    "            # Convert 'Date' column to datetime\n",
    "            data_train_df[\"Date\"] = pd.to_datetime(data_train_df[\"Date\"])\n",
    "            data_validate_df[\"Date\"] = pd.to_datetime(data_validate_df[\"Date\"])\n",
    "            data_test_df[\"Date\"] = pd.to_datetime(data_test_df[\"Date\"])\n",
    "\n",
    "            # Extract dates and features\n",
    "            features = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
    "            data_train = data_train_df[features].values\n",
    "            data_validate = data_validate_df[features].values\n",
    "            data_test = data_test_df[features].values\n",
    "\n",
    "            # Combine all datasets\n",
    "            data_all = np.concatenate([data_train, data_validate, data_test], axis=0)\n",
    "            sequence_size = 60  # Define sequence size\n",
    "\n",
    "            # Construct LSTM input/output\n",
    "            X_train, y_train = construct_lstm_data(data_train, sequence_size, 0)\n",
    "            train_size = len(data_train)\n",
    "            validate_size = len(data_validate)\n",
    "\n",
    "            X_validate, y_validate = construct_lstm_data(\n",
    "                data_all[train_size-sequence_size:train_size+validate_size], sequence_size, 0\n",
    "            )\n",
    "            X_test, y_test = construct_lstm_data(data_all[-(len(data_test) + sequence_size):], sequence_size, 0)\n",
    "\n",
    "            # Initialize the LSTM model\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            model.add(LSTM(units=100, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units=100, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units=100, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(units=100))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            # Compile the model\n",
    "            model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "            # Checkpoint to save the best model\n",
    "            checkpoint = ModelCheckpoint(model_file, monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=0)\n",
    "\n",
    "            # Train the model\n",
    "            print(\"Training LSTM model...\")\n",
    "            with tf.device('/GPU:0'):\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_data=(X_validate, y_validate),\n",
    "                    epochs=200,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1\n",
    "                )\n",
    "\n",
    "            # Plot LSTM Model Performance\n",
    "            plt.figure(figsize=(18, 6))\n",
    "            plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "            plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "            plt.title(f\"LSTM Model Performance for {ticker}\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(f\"{output_dir}{ticker.lower()}_model_performance.png\")\n",
    "            plt.show()\n",
    "\n",
    "            # Load the best model\n",
    "            best_model = load_model(model_file)\n",
    "\n",
    "            # Make future predictions\n",
    "            scaler = joblib.load(scaler_file)\n",
    "            future_predictions = predict_future(best_model, X_test[-1], days_to_predict=30, scaler=scaler)\n",
    "\n",
    "            # Visualize predictions\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(range(1, 31), future_predictions, label=\"Future Predictions\", color=\"blue\")\n",
    "            plt.title(f\"30-Day Stock Price Predictions for {ticker}\")\n",
    "            plt.xlabel(\"Days Ahead\")\n",
    "            plt.ylabel(\"Predicted Stock Price (USD)\")\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            plt.savefig(f\"{output_dir}{ticker.lower()}_30_day_predictions.png\")\n",
    "            plt.show()\n",
    "\n",
    "            print(f\"Completed processing for {ticker}.\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"All tickers processed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
